{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "! pip install tensorflow scikit-image tqdm matplotlib CairoSVG svglib reportlab keras --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of path/Data/Clean/timestamp_1:\n",
      "timestamp_1/\n",
      "    channel_0.png\n",
      "    channel_1.png\n",
      "    channel_10.png\n",
      "    channel_11.png\n",
      "    channel_2.png\n",
      "    channel_3.png\n",
      "    channel_4.png\n",
      "    channel_5.png\n",
      "    channel_6.png\n",
      "    channel_7.png\n",
      "    channel_8.png\n",
      "    channel_9.png\n",
      "    label.png\n",
      "\n",
      "Loading dataset...\n",
      "Searching for data in: path/Data/Clean/timestamp_1\n",
      "Found 13 files in path/Data/Clean/timestamp_1\n",
      "Loaded channel 0: path/Data/Clean/timestamp_1\\channel_0.png\n",
      "Loaded channel 1: path/Data/Clean/timestamp_1\\channel_1.png\n",
      "Loaded channel 2: path/Data/Clean/timestamp_1\\channel_2.png\n",
      "Loaded channel 3: path/Data/Clean/timestamp_1\\channel_3.png\n",
      "Loaded channel 4: path/Data/Clean/timestamp_1\\channel_4.png\n",
      "Loaded channel 5: path/Data/Clean/timestamp_1\\channel_5.png\n",
      "Loaded channel 6: path/Data/Clean/timestamp_1\\channel_6.png\n",
      "Loaded channel 7: path/Data/Clean/timestamp_1\\channel_7.png\n",
      "Loaded channel 8: path/Data/Clean/timestamp_1\\channel_8.png\n",
      "Loaded channel 9: path/Data/Clean/timestamp_1\\channel_9.png\n",
      "Loaded channel 10: path/Data/Clean/timestamp_1\\channel_10.png\n",
      "Loaded channel 11: path/Data/Clean/timestamp_1\\channel_11.png\n",
      "Successfully created image stack with shape: (32, 32, 4, 12)\n",
      "Loaded label: path/Data/Clean/timestamp_1\\label.png\n",
      "Total image stacks loaded: 1\n",
      "Total labels loaded: 1\n",
      "Image shape: [[[[1.9530950e-03 2.1222609e-03 1.8915802e-03 ... 1.5840061e-03\n",
      "    2.1376396e-03 2.1991543e-03]\n",
      "   [1.7377932e-03 1.8915802e-03 1.8915802e-03 ... 2.1837757e-03\n",
      "    2.0761248e-03 2.1683970e-03]\n",
      "   [1.8454441e-03 1.8608228e-03 1.7993080e-03 ... 1.8915802e-03\n",
      "    1.8454441e-03 1.7685506e-03]\n",
      "   [4.6136102e-04 3.9984621e-04 1.8454441e-04 ... 4.6136101e-05\n",
      "    3.0757402e-04 1.3840832e-04]]\n",
      "\n",
      "  [[2.0607461e-03 2.0453674e-03 1.9838526e-03 ... 2.0299887e-03\n",
      "    1.9530950e-03 1.9377163e-03]\n",
      "   [2.0761248e-03 1.9377163e-03 2.1222609e-03 ... 1.9684739e-03\n",
      "    2.2145330e-03 1.9069589e-03]\n",
      "   [1.8608228e-03 1.8146867e-03 1.8146867e-03 ... 1.8454441e-03\n",
      "    1.8146867e-03 1.9530950e-03]\n",
      "   [5.3825456e-04 2.4605924e-04 1.8454441e-04 ... 0.0000000e+00\n",
      "    2.4605924e-04 1.5378702e-05]]\n",
      "\n",
      "  [[1.7839293e-03 1.7531719e-03 2.1376396e-03 ... 1.7531719e-03\n",
      "    2.2145330e-03 2.0299887e-03]\n",
      "   [1.9530950e-03 1.9684739e-03 1.9684739e-03 ... 1.9684739e-03\n",
      "    2.0915035e-03 1.9223376e-03]\n",
      "   [2.0146100e-03 1.9530950e-03 2.0146100e-03 ... 1.9069589e-03\n",
      "    2.2914265e-03 1.9684739e-03]\n",
      "   [3.8446751e-04 1.5378702e-05 4.6136102e-04 ... 2.6143793e-04\n",
      "    1.2302962e-04 7.6893506e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.9223376e-03 1.9223376e-03 2.0607461e-03 ... 2.1068822e-03\n",
      "    1.9684739e-03 2.0607461e-03]\n",
      "   [1.9377163e-03 2.0761248e-03 1.8915802e-03 ... 1.9530950e-03\n",
      "    1.9838526e-03 1.9377163e-03]\n",
      "   [1.9223376e-03 1.7070358e-03 2.1530183e-03 ... 1.7531719e-03\n",
      "    2.1837757e-03 1.9069589e-03]\n",
      "   [1.9992310e-04 2.7681663e-04 1.8454441e-04 ... 3.3833142e-04\n",
      "    1.8454441e-04 1.9992310e-04]]\n",
      "\n",
      "  [[2.0607461e-03 2.0453674e-03 2.0915035e-03 ... 2.2145330e-03\n",
      "    2.2299117e-03 2.1991543e-03]\n",
      "   [2.3221839e-03 2.1683970e-03 2.0146100e-03 ... 2.3375626e-03\n",
      "    1.7377932e-03 2.0453674e-03]\n",
      "   [2.3375626e-03 2.1991543e-03 2.2299117e-03 ... 2.3221839e-03\n",
      "    2.1991543e-03 2.3375626e-03]\n",
      "   [3.0757402e-04 2.4605924e-04 2.4605924e-04 ... 1.3840832e-04\n",
      "    1.8454441e-04 2.1530181e-04]]\n",
      "\n",
      "  [[2.2606691e-03 1.8146867e-03 2.2452904e-03 ... 2.3221839e-03\n",
      "    1.9069589e-03 2.3836987e-03]\n",
      "   [2.3375626e-03 2.0915035e-03 2.2606691e-03 ... 2.2452904e-03\n",
      "    2.0915035e-03 2.3375626e-03]\n",
      "   [2.4605922e-03 2.2452904e-03 2.2299117e-03 ... 2.2606691e-03\n",
      "    2.0761248e-03 1.9838526e-03]\n",
      "   [3.9061899e-03 3.2295272e-04 2.1530181e-04 ... 3.6908881e-04\n",
      "    1.3840832e-04 4.7673972e-04]]]\n",
      "\n",
      "\n",
      " [[[1.6455210e-03 1.7993080e-03 1.9223376e-03 ... 1.8915802e-03\n",
      "    1.6608997e-03 1.7993080e-03]\n",
      "   [2.0299887e-03 1.7993080e-03 1.8146867e-03 ... 1.7531719e-03\n",
      "    1.7839293e-03 1.8762015e-03]\n",
      "   [2.0146100e-03 1.7070358e-03 2.1683970e-03 ... 1.4763552e-03\n",
      "    2.0299887e-03 1.8454441e-03]\n",
      "   [2.4605924e-04 3.5371011e-04 1.3840832e-04 ... 3.9984621e-04\n",
      "    1.5378702e-05 2.6143793e-04]]\n",
      "\n",
      "  [[2.0146100e-03 1.6762784e-03 1.7531719e-03 ... 1.8454441e-03\n",
      "    1.6455210e-03 1.7839293e-03]\n",
      "   [1.7685506e-03 1.9838526e-03 1.5532487e-03 ... 1.6608997e-03\n",
      "    1.5840061e-03 1.5686274e-03]\n",
      "   [1.6147635e-03 2.1530183e-03 1.8300654e-03 ... 1.7531719e-03\n",
      "    1.8762015e-03 1.6301422e-03]\n",
      "   [3.6908881e-04 1.5378701e-04 3.2295272e-04 ... 5.2287587e-04\n",
      "    1.3840832e-04 1.2302962e-04]]\n",
      "\n",
      "  [[2.1683970e-03 1.9838526e-03 1.9530950e-03 ... 1.8300654e-03\n",
      "    2.1683970e-03 1.9684739e-03]\n",
      "   [1.8915802e-03 1.7070358e-03 1.7377932e-03 ... 2.0299887e-03\n",
      "    1.9838526e-03 2.0607461e-03]\n",
      "   [1.8608228e-03 2.2145330e-03 2.0146100e-03 ... 1.8300654e-03\n",
      "    2.0607461e-03 1.8915802e-03]\n",
      "   [1.6916571e-04 2.4605924e-04 2.9219533e-04 ... 3.0757405e-05\n",
      "    3.0757402e-04 3.8446751e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.9223376e-03 1.9838526e-03 1.7070358e-03 ... 1.9530950e-03\n",
      "    2.1683970e-03 1.8454441e-03]\n",
      "   [2.0146100e-03 1.8762015e-03 1.9377163e-03 ... 1.9223376e-03\n",
      "    1.8454441e-03 2.0453674e-03]\n",
      "   [1.8146867e-03 2.1683970e-03 1.9684739e-03 ... 1.9992313e-03\n",
      "    1.9992313e-03 1.9069589e-03]\n",
      "   [1.6916571e-04 1.8454441e-04 4.7673972e-04 ... 1.5378702e-05\n",
      "    1.9992310e-04 4.6136101e-05]]\n",
      "\n",
      "  [[2.3068052e-03 2.1068822e-03 2.3529413e-03 ... 2.0761248e-03\n",
      "    2.1530183e-03 2.2914265e-03]\n",
      "   [2.3068052e-03 2.3990774e-03 2.2299117e-03 ... 2.1376396e-03\n",
      "    2.0453674e-03 2.1068822e-03]\n",
      "   [2.1068822e-03 2.1683970e-03 2.0915035e-03 ... 2.3836987e-03\n",
      "    2.1991543e-03 2.1837757e-03]\n",
      "   [1.9992310e-04 3.8292964e-03 2.1530181e-04 ... 2.3068051e-04\n",
      "    9.2272203e-05 3.9215689e-03]]\n",
      "\n",
      "  [[2.2299117e-03 2.1376396e-03 1.9838526e-03 ... 2.3068052e-03\n",
      "    2.1837757e-03 1.9223376e-03]\n",
      "   [1.8146867e-03 2.2760478e-03 2.1222609e-03 ... 2.1991543e-03\n",
      "    1.9069589e-03 2.1837757e-03]\n",
      "   [2.3683200e-03 2.1837757e-03 2.0607461e-03 ... 1.9530950e-03\n",
      "    1.9838526e-03 2.2299117e-03]\n",
      "   [2.1530181e-04 3.8446751e-03 3.0757405e-05 ... 1.5378701e-04\n",
      "    1.5378701e-04 3.8600538e-03]]]\n",
      "\n",
      "\n",
      " [[[1.7839293e-03 2.1068822e-03 1.7377932e-03 ... 1.8762015e-03\n",
      "    2.1222609e-03 1.8608228e-03]\n",
      "   [1.7685506e-03 2.3068052e-03 1.8300654e-03 ... 2.0299887e-03\n",
      "    2.0915035e-03 2.0761248e-03]\n",
      "   [1.8915802e-03 1.9377163e-03 2.2760478e-03 ... 2.2299117e-03\n",
      "    1.9530950e-03 1.9069589e-03]\n",
      "   [3.9215689e-03 3.5371011e-04 1.8454441e-04 ... 2.4605924e-04\n",
      "    2.3068051e-04 2.4605924e-04]]\n",
      "\n",
      "  [[2.1068822e-03 1.9684739e-03 1.9530950e-03 ... 2.1530183e-03\n",
      "    2.1222609e-03 2.0453674e-03]\n",
      "   [1.8454441e-03 1.9684739e-03 1.7377932e-03 ... 1.9838526e-03\n",
      "    1.9838526e-03 1.6455210e-03]\n",
      "   [1.8454441e-03 1.9684739e-03 1.7685506e-03 ... 1.9223376e-03\n",
      "    1.9992313e-03 1.9530950e-03]\n",
      "   [2.9219533e-04 1.2302962e-04 6.1514809e-05 ... 1.2302962e-04\n",
      "    3.9061899e-03 6.1514809e-05]]\n",
      "\n",
      "  [[1.8608228e-03 1.9838526e-03 1.6608997e-03 ... 1.9377163e-03\n",
      "    2.0453674e-03 1.7224145e-03]\n",
      "   [1.9530950e-03 1.9223376e-03 1.7377932e-03 ... 2.1530183e-03\n",
      "    2.0146100e-03 2.0915035e-03]\n",
      "   [1.8762015e-03 1.9992313e-03 2.1991543e-03 ... 1.6762784e-03\n",
      "    2.0146100e-03 1.8608228e-03]\n",
      "   [1.5378701e-04 3.0757402e-04 3.8139177e-03 ... 3.9984621e-04\n",
      "    4.9211847e-04 2.9219533e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.1376396e-03 1.9992313e-03 2.0607461e-03 ... 1.7224145e-03\n",
      "    1.8915802e-03 1.9530950e-03]\n",
      "   [1.8608228e-03 1.9069589e-03 1.8915802e-03 ... 1.9223376e-03\n",
      "    1.6916571e-03 2.0607461e-03]\n",
      "   [1.8454441e-03 1.6455210e-03 1.8915802e-03 ... 1.9992313e-03\n",
      "    1.8608228e-03 1.8454441e-03]\n",
      "   [3.8600538e-03 2.6143793e-04 3.0757402e-04 ... 1.6916571e-04\n",
      "    1.3840832e-04 3.0757405e-05]]\n",
      "\n",
      "  [[2.1837757e-03 2.2760478e-03 2.2145330e-03 ... 2.1376396e-03\n",
      "    2.1837757e-03 2.2914265e-03]\n",
      "   [1.9377163e-03 1.9838526e-03 2.0915035e-03 ... 2.3683200e-03\n",
      "    2.4298348e-03 2.3375626e-03]\n",
      "   [2.0915035e-03 2.1837757e-03 2.1683970e-03 ... 2.2760478e-03\n",
      "    2.2145330e-03 2.3375626e-03]\n",
      "   [4.6136101e-05 4.1522493e-04 1.5378701e-04 ... 3.8754325e-03\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[2.3068052e-03 2.2914265e-03 2.1068822e-03 ... 2.3836987e-03\n",
      "    2.2760478e-03 2.0761248e-03]\n",
      "   [1.9684739e-03 2.3068052e-03 2.1530183e-03 ... 2.0761248e-03\n",
      "    2.1068822e-03 2.1376396e-03]\n",
      "   [2.3990774e-03 2.0761248e-03 2.3221839e-03 ... 2.1683970e-03\n",
      "    2.2452904e-03 2.3375626e-03]\n",
      "   [7.6893506e-05 1.0765091e-04 3.6908881e-04 ... 1.3840832e-04\n",
      "    1.3840832e-04 7.6893506e-05]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[2.1837757e-03 2.0453674e-03 2.1068822e-03 ... 1.5071126e-03\n",
      "    2.0607461e-03 1.6916571e-03]\n",
      "   [1.9530950e-03 2.0146100e-03 1.9684739e-03 ... 2.0761248e-03\n",
      "    1.9377163e-03 1.9684739e-03]\n",
      "   [1.8454441e-03 1.9684739e-03 1.9684739e-03 ... 1.7993080e-03\n",
      "    1.9530950e-03 1.9530950e-03]\n",
      "   [1.3840832e-04 3.9061899e-03 2.3068051e-04 ... 2.1530181e-04\n",
      "    1.8454441e-04 2.7681663e-04]]\n",
      "\n",
      "  [[1.9377163e-03 2.1068822e-03 1.8146867e-03 ... 1.9530950e-03\n",
      "    1.9684739e-03 2.1222609e-03]\n",
      "   [1.9530950e-03 2.2145330e-03 2.0761248e-03 ... 1.9223376e-03\n",
      "    2.0761248e-03 2.0146100e-03]\n",
      "   [2.0299887e-03 1.8454441e-03 1.9684739e-03 ... 1.8608228e-03\n",
      "    2.1837757e-03 1.9377163e-03]\n",
      "   [1.8454441e-04 1.2302962e-04 1.8454441e-04 ... 3.9984621e-04\n",
      "    1.5378701e-04 6.1514809e-05]]\n",
      "\n",
      "  [[2.0146100e-03 1.9838526e-03 2.0299887e-03 ... 1.8762015e-03\n",
      "    1.8454441e-03 1.7070358e-03]\n",
      "   [1.9530950e-03 1.5993848e-03 1.8915802e-03 ... 1.8454441e-03\n",
      "    2.0146100e-03 1.9992313e-03]\n",
      "   [2.0607461e-03 2.2606691e-03 1.7839293e-03 ... 2.0607461e-03\n",
      "    2.0299887e-03 1.9530950e-03]\n",
      "   [2.1530181e-04 2.7681663e-04 1.2302962e-04 ... 6.1514809e-05\n",
      "    4.6136101e-05 2.1530181e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.1683970e-03 2.0761248e-03 1.8146867e-03 ... 1.8608228e-03\n",
      "    1.7993080e-03 1.9377163e-03]\n",
      "   [2.2914265e-03 2.0761248e-03 2.0915035e-03 ... 2.0915035e-03\n",
      "    2.1376396e-03 1.9223376e-03]\n",
      "   [2.1530183e-03 1.9069589e-03 2.0299887e-03 ... 1.9223376e-03\n",
      "    2.0146100e-03 2.0299887e-03]\n",
      "   [2.6143793e-04 1.8454441e-04 7.6893506e-05 ... 3.9215689e-03\n",
      "    1.2302962e-04 7.6893506e-05]]\n",
      "\n",
      "  [[2.2760478e-03 2.2299117e-03 2.0146100e-03 ... 2.2299117e-03\n",
      "    1.9377163e-03 2.0453674e-03]\n",
      "   [2.3683200e-03 2.2145330e-03 2.2452904e-03 ... 2.4452135e-03\n",
      "    1.9992313e-03 2.2145330e-03]\n",
      "   [2.1530183e-03 2.2760478e-03 1.8300654e-03 ... 2.0146100e-03\n",
      "    2.3529413e-03 2.1837757e-03]\n",
      "   [3.9984621e-04 2.9219533e-04 1.2302962e-04 ... 1.6916571e-04\n",
      "    0.0000000e+00 4.6136101e-05]]\n",
      "\n",
      "  [[2.1222609e-03 2.3683200e-03 2.4298348e-03 ... 2.3221839e-03\n",
      "    1.8762015e-03 2.3221839e-03]\n",
      "   [2.3068052e-03 2.1376396e-03 2.1837757e-03 ... 1.9069589e-03\n",
      "    1.9069589e-03 2.1683970e-03]\n",
      "   [2.1222609e-03 1.9684739e-03 2.3375626e-03 ... 2.2299117e-03\n",
      "    2.4144561e-03 2.2299117e-03]\n",
      "   [1.6916571e-04 3.0757402e-04 3.8446751e-04 ... 2.4605924e-04\n",
      "    1.9992310e-04 3.0757405e-05]]]\n",
      "\n",
      "\n",
      " [[[2.3836987e-03 2.3683200e-03 2.4298348e-03 ... 2.3836987e-03\n",
      "    2.1683970e-03 2.1068822e-03]\n",
      "   [2.3683200e-03 2.1068822e-03 2.3068052e-03 ... 2.0915035e-03\n",
      "    2.4452135e-03 2.2145330e-03]\n",
      "   [2.1068822e-03 1.9838526e-03 2.2914265e-03 ... 2.3221839e-03\n",
      "    2.2145330e-03 1.9684739e-03]\n",
      "   [9.2272203e-05 2.6143793e-04 3.7524030e-03 ... 5.9976935e-04\n",
      "    3.0757405e-05 1.2302962e-04]]\n",
      "\n",
      "  [[2.0915035e-03 2.1683970e-03 2.0761248e-03 ... 2.2760478e-03\n",
      "    2.0453674e-03 2.1837757e-03]\n",
      "   [1.9377163e-03 2.1837757e-03 2.1376396e-03 ... 2.0607461e-03\n",
      "    2.1991543e-03 2.1530183e-03]\n",
      "   [1.7377932e-03 2.0915035e-03 2.1683970e-03 ... 2.0607461e-03\n",
      "    2.0915035e-03 2.3375626e-03]\n",
      "   [1.3840832e-04 2.6143793e-04 2.9219533e-04 ... 3.8600538e-03\n",
      "    3.9984621e-04 3.8754325e-03]]\n",
      "\n",
      "  [[2.0607461e-03 2.4452135e-03 2.3068052e-03 ... 2.0299887e-03\n",
      "    2.0761248e-03 2.1068822e-03]\n",
      "   [2.2452904e-03 2.0915035e-03 2.1068822e-03 ... 2.1068822e-03\n",
      "    2.0299887e-03 2.0146100e-03]\n",
      "   [2.1837757e-03 1.8762015e-03 1.9992313e-03 ... 2.1991543e-03\n",
      "    2.1991543e-03 2.1991543e-03]\n",
      "   [1.3840832e-04 3.9215689e-03 3.6908881e-04 ... 1.5378702e-05\n",
      "    1.3840832e-04 2.7681663e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.2760478e-03 2.0146100e-03 2.0453674e-03 ... 2.3221839e-03\n",
      "    2.0761248e-03 1.9684739e-03]\n",
      "   [2.1222609e-03 2.3068052e-03 2.1530183e-03 ... 2.1222609e-03\n",
      "    2.2299117e-03 2.1991543e-03]\n",
      "   [2.0761248e-03 2.0453674e-03 2.0607461e-03 ... 2.2760478e-03\n",
      "    2.0607461e-03 2.0453674e-03]\n",
      "   [1.3840832e-04 1.3840832e-04 3.8139177e-03 ... 3.2295272e-04\n",
      "    9.2272203e-05 1.3840832e-04]]\n",
      "\n",
      "  [[2.0607461e-03 2.1222609e-03 1.7531719e-03 ... 1.9684739e-03\n",
      "    2.0146100e-03 1.9684739e-03]\n",
      "   [1.8915802e-03 2.1376396e-03 1.9684739e-03 ... 1.9992313e-03\n",
      "    1.9838526e-03 1.9223376e-03]\n",
      "   [1.6916571e-03 1.7070358e-03 1.8300654e-03 ... 2.1376396e-03\n",
      "    2.0299887e-03 2.0453674e-03]\n",
      "   [2.4605924e-04 3.7831604e-03 2.6143793e-04 ... 1.9992310e-04\n",
      "    3.9215689e-03 3.8292964e-03]]\n",
      "\n",
      "  [[2.0607461e-03 1.9223376e-03 1.9684739e-03 ... 1.7839293e-03\n",
      "    1.9069589e-03 1.8762015e-03]\n",
      "   [2.0607461e-03 2.0453674e-03 2.0146100e-03 ... 1.8300654e-03\n",
      "    1.6608997e-03 2.2299117e-03]\n",
      "   [1.9838526e-03 2.0453674e-03 2.3221839e-03 ... 1.7993080e-03\n",
      "    1.9992313e-03 2.0453674e-03]\n",
      "   [3.8600538e-03 3.3833142e-04 3.0757402e-04 ... 3.7062669e-03\n",
      "    2.9219533e-04 1.3840832e-04]]]\n",
      "\n",
      "\n",
      " [[[2.2145330e-03 2.2452904e-03 2.2145330e-03 ... 2.1530183e-03\n",
      "    2.2299117e-03 2.1222609e-03]\n",
      "   [2.1222609e-03 2.0607461e-03 2.2606691e-03 ... 2.2760478e-03\n",
      "    2.0607461e-03 2.4605922e-03]\n",
      "   [1.9992313e-03 1.8608228e-03 2.3836987e-03 ... 2.1837757e-03\n",
      "    2.0761248e-03 2.3375626e-03]\n",
      "   [3.0757405e-05 2.9219533e-04 1.3840832e-04 ... 3.2295272e-04\n",
      "    1.2302962e-04 1.5378701e-04]]\n",
      "\n",
      "  [[2.3068052e-03 1.9684739e-03 2.3221839e-03 ... 2.0453674e-03\n",
      "    2.1837757e-03 1.8454441e-03]\n",
      "   [1.9530950e-03 2.1530183e-03 2.1683970e-03 ... 2.3221839e-03\n",
      "    2.1683970e-03 2.4144561e-03]\n",
      "   [2.3836987e-03 2.1068822e-03 2.1991543e-03 ... 2.4144561e-03\n",
      "    2.2606691e-03 1.9684739e-03]\n",
      "   [3.9061899e-03 2.9219533e-04 3.3833142e-04 ... 2.3068051e-04\n",
      "    2.3068051e-04 2.9219533e-04]]\n",
      "\n",
      "  [[2.3068052e-03 1.9992313e-03 2.0146100e-03 ... 2.3375626e-03\n",
      "    2.2452904e-03 1.9992313e-03]\n",
      "   [2.3221839e-03 2.2452904e-03 2.3375626e-03 ... 2.1683970e-03\n",
      "    1.9838526e-03 2.3529413e-03]\n",
      "   [1.9684739e-03 2.2606691e-03 2.0761248e-03 ... 2.4144561e-03\n",
      "    2.4144561e-03 2.0146100e-03]\n",
      "   [1.5378701e-04 9.2272203e-05 3.8908112e-03 ... 3.5371011e-04\n",
      "    1.8454441e-04 4.6136101e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.1530183e-03 2.2760478e-03 2.1683970e-03 ... 2.3068052e-03\n",
      "    1.9684739e-03 2.3529413e-03]\n",
      "   [2.2914265e-03 2.3221839e-03 1.9530950e-03 ... 2.1376396e-03\n",
      "    2.1530183e-03 2.1991543e-03]\n",
      "   [2.0761248e-03 2.3529413e-03 2.0146100e-03 ... 2.0915035e-03\n",
      "    2.2606691e-03 2.1222609e-03]\n",
      "   [3.8908112e-03 2.4605924e-04 3.8754325e-03 ... 3.8446751e-03\n",
      "    3.2295272e-04 7.6893506e-05]]\n",
      "\n",
      "  [[2.0761248e-03 1.8300654e-03 1.9530950e-03 ... 1.9377163e-03\n",
      "    1.9838526e-03 1.8608228e-03]\n",
      "   [1.8762015e-03 2.0453674e-03 1.9223376e-03 ... 1.8762015e-03\n",
      "    1.9992313e-03 2.2452904e-03]\n",
      "   [1.9684739e-03 2.1222609e-03 2.2760478e-03 ... 2.0761248e-03\n",
      "    1.8915802e-03 2.0915035e-03]\n",
      "   [3.8292964e-03 3.2295272e-04 3.9061899e-03 ... 3.9061899e-03\n",
      "    3.0757405e-05 3.8600538e-03]]\n",
      "\n",
      "  [[1.7839293e-03 2.0607461e-03 2.1222609e-03 ... 2.0146100e-03\n",
      "    1.6762784e-03 1.8146867e-03]\n",
      "   [1.6916571e-03 1.9992313e-03 2.0299887e-03 ... 2.0453674e-03\n",
      "    1.7993080e-03 2.1068822e-03]\n",
      "   [1.8608228e-03 1.9377163e-03 1.8762015e-03 ... 2.1683970e-03\n",
      "    2.0453674e-03 2.1222609e-03]\n",
      "   [1.0765091e-04 6.1514809e-05 2.3068051e-04 ... 1.6916571e-04\n",
      "    4.6136101e-05 1.5378702e-05]]]]\n",
      "Preparing data for model...\n",
      "Labels shape before reshape: (1, 32, 32, 4)\n",
      "Labels content before reshape: [[[[1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   ...\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]]\n",
      "\n",
      "  [[1.8146867e-03 1.8146867e-03 1.8146867e-03 1.9992310e-04]\n",
      "   [1.8146867e-03 1.8146867e-03 1.8146867e-03 1.9992310e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   ...\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]]\n",
      "\n",
      "  [[1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   ...\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 1.8454441e-04]\n",
      "   ...\n",
      "   [1.8146867e-03 1.8146867e-03 2.1068822e-03 1.9992310e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]]\n",
      "\n",
      "  [[2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   ...\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 9.2272203e-05]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 9.2272203e-05]]\n",
      "\n",
      "  [[2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   ...\n",
      "   [2.1837757e-03 2.1837757e-03 2.1837757e-03 1.3840832e-04]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 9.2272203e-05]\n",
      "   [1.9684739e-03 1.9684739e-03 1.9684739e-03 9.2272203e-05]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 251\u001b[0m\n\u001b[0;32m    248\u001b[0m     exit(code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing data for model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 251\u001b[0m X_train, X_val, X_test, y_train, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    255\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m load_dataset(data_dir, target_size)\n",
      "Cell \u001b[1;32mIn[31], line 78\u001b[0m, in \u001b[0;36mprepare_data_for_model\u001b[1;34m(images, labels, test_size, validation_split)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels array is empty. Please check the data loading process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mreshape(labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m X_train_val, X_test, y_train_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     82\u001b[0m     X_train_val, y_train_val, test_size\u001b[38;5;241m=\u001b[39mvalidation_split, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_train, X_val, X_test, y_train, y_val, y_test\n",
      "File \u001b[1;32mc:\\Users\\Denzi\\OneDrive\\Documents\\GitHub\\Python_Scripts\\Lighting predictions\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Denzi\\OneDrive\\Documents\\GitHub\\Python_Scripts\\Lighting predictions\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2780\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Denzi\\OneDrive\\Documents\\GitHub\\Python_Scripts\\Lighting predictions\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2410\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2407\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2414\u001b[0m     )\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from skimage import io,transform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Data Ingestion\n",
    "\n",
    "def load_and_preprocess_image(file_path, target_size=(32, 32)):\n",
    "    \"\"\"Load and preprocess a single satellite image.\"\"\"\n",
    "    img = io.imread(file_path)\n",
    "    img = transform.resize(img, target_size, anti_aliasing=True)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "def load_dataset(data_dir, target_size=(32, 32)):\n",
    "    \"\"\"Load all images and labels from the data directory.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"Searching for data in: {data_dir}\")\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: Directory {data_dir} does not exist.\")\n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    files = os.listdir(data_dir)\n",
    "    print(f\"Found {len(files)} files in {data_dir}\")\n",
    "    \n",
    "    timestamp_images = []\n",
    "    for i in range(12):\n",
    "        img_path = os.path.join(data_dir, f'channel_{i}.png')\n",
    "        if os.path.exists(img_path):\n",
    "            img = load_and_preprocess_image(img_path, target_size)\n",
    "            timestamp_images.append(img)\n",
    "            print(f\"Loaded channel {i}: {img_path}\")\n",
    "        else:\n",
    "            print(f\"Missing image: {img_path}\")\n",
    "    \n",
    "    if len(timestamp_images) == 12:\n",
    "        image_stack = np.stack(timestamp_images, axis=-1)\n",
    "        images.append(image_stack)\n",
    "        print(f\"Successfully created image stack with shape: {image_stack.shape}\")\n",
    "        \n",
    "        label_path = os.path.join(data_dir, 'label.png')\n",
    "        if os.path.exists(label_path):\n",
    "            label = io.imread(label_path)\n",
    "            label = load_and_preprocess_image(label_path, target_size)\n",
    "            labels.append(label)\n",
    "            print(f\"Loaded label: {label_path}\")\n",
    "        else:\n",
    "            print(f\"Missing label: {label_path}\")\n",
    "    else:\n",
    "        print(f\"Incomplete channel set in {data_dir}. Found {len(timestamp_images)} channels instead of 12.\")\n",
    "    \n",
    "    print(f\"Total image stacks loaded: {len(images)}\")\n",
    "    print(f\"Total labels loaded: {len(labels)}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "def prepare_data_for_model(images, labels, test_size=0.2, validation_split=0.2):\n",
    "    \"\"\"Prepare the data for model training, including train/val/test split.\"\"\"\n",
    "    # Debugging: Print the shape and content of labels\n",
    "    print(f\"Labels shape before reshape: {labels.shape}\")\n",
    "    print(f\"Labels content before reshape: {labels}\")\n",
    "\n",
    "    if labels.size == 0:\n",
    "        raise ValueError(\"Labels array is empty. Please check the data loading process.\")\n",
    "\n",
    "    labels = labels.reshape(labels.shape[0], -1)\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        images, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=validation_split, random_state=42)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def data_generator(images, labels, batch_size=32):\n",
    "    \"\"\"Generator to yield batches of data.\"\"\"\n",
    "    num_samples = len(images)\n",
    "    while True:\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            yield images[batch_indices], labels[batch_indices]\n",
    "\n",
    "# Model Architecture\n",
    "\n",
    "def create_lightning_cnn(input_shape=(32, 32, 12), num_classes=1024):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        \n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compile_model(model, learning_rate=1e-3, decay=0.9):\n",
    "    lr_schedule = optimizers.schedules.InverseTimeDecay(\n",
    "        initial_learning_rate=learning_rate,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=decay\n",
    "    )\n",
    "    optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Model Training\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size=128, epochs=3000):\n",
    "    neg, pos = np.bincount(y_train.flatten())\n",
    "    total = neg + pos\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.2, patience=20)\n",
    "\n",
    "    train_gen = data_generator(X_train, y_train, batch_size)\n",
    "    val_gen = data_generator(X_val, y_val, batch_size)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=len(X_train) // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=len(X_val) // batch_size,\n",
    "        class_weight=class_weight,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Performance Visualization\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true.ravel(), y_pred.ravel())\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(y_true, y_pred, num_samples=5):\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(0, y_true.shape[0])\n",
    "        \n",
    "        axes[i, 0].imshow(y_true[idx].reshape(32, 32), cmap='binary')\n",
    "        axes[i, 0].set_title(f'True - Sample {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(y_pred[idx].reshape(32, 32), cmap='binary')\n",
    "        axes[i, 1].set_title(f'Predicted - Sample {i+1}')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main Execution\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Data Ingestion\n",
    "    data_dir = 'path/Data/Clean/timestamp_1'\n",
    "    target_size = (32, 32)\n",
    "    batch_size = 32\n",
    "    \n",
    "    print(f\"Contents of {data_dir}:\")\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        level = root.replace(data_dir, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f\"{subindent}{f}\")\n",
    "    \n",
    "    print(\"\\nLoading dataset...\")\n",
    "    images, labels = load_dataset(data_dir, target_size)\n",
    "    for image in images:\n",
    "        print(f\"Image shape: {image}\")\n",
    "\n",
    "    \n",
    "    if len(images) == 0 or len(labels) == 0:\n",
    "        print(\"Error: No images or labels were loaded. Please check the data directory and file structure.\")\n",
    "        exit(code=1)\n",
    "    \n",
    "    print(\"Preparing data for model...\")\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_for_model(images, labels)\n",
    "    \n",
    "    \n",
    "    print(\"Loading dataset...\")\n",
    "    images, labels = load_dataset(data_dir, target_size)\n",
    "    \n",
    "    print(\"Preparing data for model...\")\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_for_model(images, labels)\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    print(f\"Validation samples: {len(X_val)}\")\n",
    "    print(f\"Test samples: {len(X_test)}\")\n",
    "    \n",
    "    # Model Creation and Training\n",
    "    input_shape = (32, 32, 12)\n",
    "    num_classes = 1024\n",
    "    \n",
    "    model = create_lightning_cnn(input_shape, num_classes)\n",
    "    model = compile_model(model)\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    print(\"Evaluating model...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    \n",
    "    # Generate predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Visualize Results\n",
    "    plot_training_history(history)\n",
    "    plot_precision_recall_curve(y_test, y_pred)\n",
    "    plot_roc_curve(y_test, y_pred)\n",
    "    visualize_predictions(y_test, y_pred)\n",
    "    \n",
    "    # Print best outcomes\n",
    "    print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of path/Data/Clean/timestamp_1:\n",
      "timestamp_1/\n",
      "    channel_0.png\n",
      "    channel_1.png\n",
      "    channel_10.png\n",
      "    channel_11.png\n",
      "    channel_2.png\n",
      "    channel_3.png\n",
      "    channel_4.png\n",
      "    channel_5.png\n",
      "    channel_6.png\n",
      "    channel_7.png\n",
      "    channel_8.png\n",
      "    channel_9.png\n",
      "    label.png\n",
      "\n",
      "Loading dataset...\n",
      "Searching for data in: path/Data/Clean/timestamp_1\n",
      "Loaded channel 0: path/Data/Clean/timestamp_1\\channel_0.png\n",
      "Loaded channel 1: path/Data/Clean/timestamp_1\\channel_1.png\n",
      "Loaded channel 2: path/Data/Clean/timestamp_1\\channel_2.png\n",
      "Loaded channel 3: path/Data/Clean/timestamp_1\\channel_3.png\n",
      "Loaded channel 4: path/Data/Clean/timestamp_1\\channel_4.png\n",
      "Loaded channel 5: path/Data/Clean/timestamp_1\\channel_5.png\n",
      "Loaded channel 6: path/Data/Clean/timestamp_1\\channel_6.png\n",
      "Loaded channel 7: path/Data/Clean/timestamp_1\\channel_7.png\n",
      "Loaded channel 8: path/Data/Clean/timestamp_1\\channel_8.png\n",
      "Loaded channel 9: path/Data/Clean/timestamp_1\\channel_9.png\n",
      "Loaded channel 10: path/Data/Clean/timestamp_1\\channel_10.png\n",
      "Loaded channel 11: path/Data/Clean/timestamp_1\\channel_11.png\n",
      "Successfully created image stack with shape: (32, 32, 4, 12)\n",
      "Loaded label: path/Data/Clean/timestamp_1\\label.png\n",
      "Total image stacks loaded: 1\n",
      "Total labels loaded: 1\n",
      "\n",
      "Number of samples: 1\n",
      "Shape of first image stack: (32, 32, 4, 12)\n",
      "Shape of first label: (32, 32, 4)\n",
      "\n",
      "Preparing data for model...\n",
      "Images shape: (1, 32, 32, 4, 12)\n",
      "Labels shape before reshape: (1, 32, 32, 4)\n",
      "Labels unique values: [6.1514809e-05 7.6893506e-05 9.2272203e-05 1.0765091e-04 1.3840832e-04\n",
      " 1.5378701e-04 1.6916571e-04 1.8454441e-04 1.9992310e-04 2.1530181e-04\n",
      " 2.3068051e-04 2.7681663e-04 3.0757402e-04 3.2295272e-04 3.3833142e-04\n",
      " 3.5371011e-04 3.6908881e-04 3.8446751e-04 3.9984621e-04 4.3060363e-04\n",
      " 4.4598232e-04 4.6136102e-04 5.0749717e-04 5.3825456e-04 5.5363326e-04\n",
      " 5.9976935e-04 6.3052675e-04 6.6128414e-04 7.5355632e-04 7.6893502e-04\n",
      " 7.8431371e-04 7.9969241e-04 8.1507111e-04 8.3044986e-04 8.4582856e-04\n",
      " 8.6120726e-04 8.9196465e-04 9.0734335e-04 9.3810074e-04 9.5347944e-04\n",
      " 9.6885813e-04 9.8423695e-04 1.0149943e-03 1.0457517e-03 1.0611304e-03\n",
      " 1.0765091e-03 1.1072665e-03 1.1995387e-03 1.2302961e-03 1.2456748e-03\n",
      " 1.2610535e-03 1.2764322e-03 1.2918109e-03 1.3071896e-03 1.3225683e-03\n",
      " 1.3533257e-03 1.3994618e-03 1.4455979e-03 1.5532487e-03 1.5686274e-03\n",
      " 1.5993848e-03 1.6455210e-03 1.6608997e-03 1.6762784e-03 1.7839293e-03\n",
      " 1.7993080e-03 1.8146867e-03 1.8762015e-03 1.9069589e-03 1.9223376e-03\n",
      " 1.9530950e-03 1.9684739e-03 2.0299887e-03 2.0607461e-03 2.0761248e-03\n",
      " 2.0915035e-03 2.1068822e-03 2.1222609e-03 2.1376396e-03 2.1837757e-03\n",
      " 2.2452904e-03 2.2606691e-03 2.2760478e-03 2.3221839e-03 2.3529413e-03\n",
      " 2.3836987e-03 2.4452135e-03 2.4605922e-03 2.4913496e-03 2.5067283e-03\n",
      " 2.5221070e-03 2.5374857e-03 2.5528644e-03 2.5682431e-03 2.5836218e-03\n",
      " 2.5990005e-03 2.6143792e-03 2.6297579e-03 2.6451366e-03 2.6605153e-03\n",
      " 2.6758939e-03 2.7835448e-03 2.9219531e-03 2.9373318e-03 3.0296040e-03\n",
      " 3.0449827e-03 3.0603614e-03 3.0911188e-03 3.1064975e-03 3.1526336e-03\n",
      " 3.1680122e-03 3.1987696e-03 3.2141483e-03 3.2295270e-03 3.2449057e-03\n",
      " 3.2602844e-03 3.2756634e-03 3.2910421e-03 3.3064208e-03 3.3217994e-03\n",
      " 3.3371781e-03 3.3525568e-03 3.3679355e-03 3.3833142e-03 3.3986929e-03\n",
      " 3.4140716e-03 3.4294503e-03 3.4448290e-03 3.4602077e-03 3.4755864e-03\n",
      " 3.4909651e-03 3.5063438e-03 3.5371012e-03 3.5524799e-03 3.5832373e-03\n",
      " 3.5986160e-03 3.6908882e-03 3.7062669e-03 3.7216456e-03]\n",
      "Labels shape after reshape: (1, 4096)\n",
      "Warning: Only 1 samples found. Splitting may not be possible.\n",
      "X_train shape: (1, 32, 32, 4, 12)\n",
      "y_train shape: (1, 4096)\n",
      "X_val shape: (1, 32, 32, 4, 12)\n",
      "y_val shape: (1, 4096)\n",
      "\n",
      "Training samples: 1\n",
      "Validation samples: 1\n",
      "Test samples: 1\n",
      "Training model...\n",
      "Epoch 1/3000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 4096), output.shape=(None, 1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 294\u001b[0m\n\u001b[0;32m    291\u001b[0m model \u001b[38;5;241m=\u001b[39m compile_model(model)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 294\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;66;03m# Model Evaluation\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 172\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, y_train, X_val, y_val, batch_size, epochs)\u001b[0m\n\u001b[0;32m    169\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m data_generator(X_train, y_train, class_weights, batch_size)\n\u001b[0;32m    170\u001b[0m val_gen \u001b[38;5;241m=\u001b[39m data_generator(X_val, y_val, class_weights, batch_size)\n\u001b[1;32m--> 172\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\Denzi\\OneDrive\\Documents\\GitHub\\Python_Scripts\\Lighting predictions\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Denzi\\OneDrive\\Documents\\GitHub\\Python_Scripts\\Lighting predictions\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:701\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[1;34m(target, output, from_logits)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[1;32m--> 701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    702\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    703\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    707\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[0;32m    708\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    709\u001b[0m )\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 4096), output.shape=(None, 1024)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Ingestion\n",
    "\n",
    "def load_and_preprocess_image(file_path, target_size=(32, 32)):\n",
    "    \"\"\"Load and preprocess a single satellite image.\"\"\"\n",
    "    img = io.imread(file_path)\n",
    "    img = transform.resize(img, target_size, anti_aliasing=True)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "def load_dataset(data_dir, target_size=(32, 32)):\n",
    "    \"\"\"Load all images and labels from the data directory.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"Searching for data in: {data_dir}\")\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: Directory {data_dir} does not exist.\")\n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    # Check if data_dir is a single timestamp directory or contains multiple timestamp directories\n",
    "    if all(f.startswith('channel_') or f == 'label.png' for f in os.listdir(data_dir)):\n",
    "        # Single timestamp directory\n",
    "        directories = [data_dir]\n",
    "    else:\n",
    "        # Multiple timestamp directories\n",
    "        directories = [os.path.join(data_dir, d) for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    \n",
    "    for directory in directories:\n",
    "        timestamp_images = []\n",
    "        for i in range(12):\n",
    "            img_path = os.path.join(directory, f'channel_{i}.png')\n",
    "            if os.path.exists(img_path):\n",
    "                img = load_and_preprocess_image(img_path, target_size)\n",
    "                timestamp_images.append(img)\n",
    "                print(f\"Loaded channel {i}: {img_path}\")\n",
    "            else:\n",
    "                print(f\"Missing image: {img_path}\")\n",
    "        \n",
    "        if len(timestamp_images) == 12:\n",
    "            image_stack = np.stack(timestamp_images, axis=-1)\n",
    "            images.append(image_stack)\n",
    "            print(f\"Successfully created image stack with shape: {image_stack.shape}\")\n",
    "            \n",
    "            label_path = os.path.join(directory, 'label.png')\n",
    "            if os.path.exists(label_path):\n",
    "                label = io.imread(label_path)\n",
    "                label = load_and_preprocess_image(label_path, target_size)\n",
    "                labels.append(label)\n",
    "                print(f\"Loaded label: {label_path}\")\n",
    "            else:\n",
    "                print(f\"Missing label: {label_path}\")\n",
    "        else:\n",
    "            print(f\"Incomplete channel set in {directory}. Found {len(timestamp_images)} channels instead of 12.\")\n",
    "    \n",
    "    print(f\"Total image stacks loaded: {len(images)}\")\n",
    "    print(f\"Total labels loaded: {len(labels)}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def prepare_data_for_model(images, labels, test_size=0.2, validation_split=0.2):\n",
    "    \"\"\"Prepare the data for model training, including train/val/test split.\"\"\"\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape before reshape: {labels.shape}\")\n",
    "    print(f\"Labels unique values: {np.unique(labels)}\")\n",
    "\n",
    "    if labels.size == 0:\n",
    "        raise ValueError(\"Labels array is empty. Please check the data loading process.\")\n",
    "\n",
    "    labels = labels.reshape(labels.shape[0], -1)\n",
    "    print(f\"Labels shape after reshape: {labels.shape}\")\n",
    "\n",
    "    n_samples = len(images)\n",
    "    if n_samples < 3:\n",
    "        print(f\"Warning: Only {n_samples} samples found. Splitting may not be possible.\")\n",
    "        return images, images, images, labels, labels, labels\n",
    "\n",
    "    if n_samples < 10:\n",
    "        print(f\"Warning: Only {n_samples} samples found. Using a 60/20/20 split.\")\n",
    "        test_size = 0.2\n",
    "        validation_split = 0.25  # 25% of 80% is 20% of the total\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        images, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=validation_split, random_state=42)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def data_generator(images, labels, class_weights, batch_size=32):\n",
    "    \"\"\"Generator to yield batches of data with class weighting.\"\"\"\n",
    "    num_samples = len(images)\n",
    "    while True:\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_images = images[batch_indices]\n",
    "            # Assuming the original shape is (32, 32, 48)\n",
    "            # Reshape to (batch_size, 32, 32, 12, 4) and then take the mean along the last axis\n",
    "            batch_images = batch_images.reshape(-1, 32, 32, 12, 4).mean(axis=-1)\n",
    "            batch_labels = labels[batch_indices]\n",
    "            batch_weights = np.array([class_weights[label] for label in batch_labels.flatten()])\n",
    "            yield batch_images, batch_labels, batch_weights\n",
    "\n",
    "# Model Architecture\n",
    "\n",
    "def create_lightning_cnn(input_shape=(32, 32, 12), num_classes=1024):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        \n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compile_model(model, learning_rate=1e-3, decay=0.9):\n",
    "    lr_schedule = optimizers.schedules.InverseTimeDecay(\n",
    "        initial_learning_rate=learning_rate,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=decay\n",
    "    )\n",
    "    optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Model Training\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size=128, epochs=3000):\n",
    "    # Calculate class weights\n",
    "    unique, counts = np.unique(y_train.flatten(), return_counts=True)\n",
    "    class_weights = dict(zip(unique, len(y_train.flatten()) / (len(unique) * counts)))\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.2, patience=20)\n",
    "\n",
    "    train_gen = data_generator(X_train, y_train, class_weights, batch_size)\n",
    "    val_gen = data_generator(X_val, y_val, class_weights, batch_size)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=len(X_train) // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=len(X_val) // batch_size,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Performance Visualization\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true.ravel(), y_pred.ravel())\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(y_true, y_pred, num_samples=5):\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(0, y_true.shape[0])\n",
    "        \n",
    "        axes[i, 0].imshow(y_true[idx].reshape(32, 32), cmap='binary')\n",
    "        axes[i, 0].set_title(f'True - Sample {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(y_pred[idx].reshape(32, 32), cmap='binary')\n",
    "        axes[i, 1].set_title(f'Predicted - Sample {i+1}')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main Execution\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Data Ingestion\n",
    "    data_dir = 'path/Data/Clean/timestamp_1'\n",
    "    target_size = (32, 32)\n",
    "    batch_size = 32\n",
    "    \n",
    "    print(f\"Contents of {data_dir}:\")\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        level = root.replace(data_dir, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f\"{subindent}{f}\")\n",
    "    \n",
    "    print(\"\\nLoading dataset...\")\n",
    "    images, labels = load_dataset(data_dir, target_size)\n",
    "    \n",
    "    print(f\"\\nNumber of samples: {len(images)}\")\n",
    "    print(f\"Shape of first image stack: {images[0].shape if len(images) > 0 else 'No images'}\")\n",
    "    print(f\"Shape of first label: {labels[0].shape if len(labels) > 0 else 'No labels'}\")\n",
    "\n",
    "    if len(images) == 0 or len(labels) == 0:\n",
    "        print(\"Error: No images or labels were loaded. Please check the data directory and file structure.\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"\\nPreparing data for model...\")\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_for_model(images, labels)\n",
    "    \n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"X_val shape:\", X_val.shape)\n",
    "    print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "    print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "    print(f\"Validation samples: {len(X_val)}\")\n",
    "    print(f\"Test samples: {len(X_test)}\")\n",
    "    \n",
    "    # Model Creation and Training\n",
    "    input_shape = (32, 32, 12)\n",
    "    num_classes = 1024\n",
    "    \n",
    "    model = create_lightning_cnn(input_shape, num_classes)\n",
    "    model = compile_model(model)\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    print(\"Evaluating model...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    \n",
    "    # Generate predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Visualize Results\n",
    "    plot_training_history(history)\n",
    "    plot_precision_recall_curve(y_test, y_pred)\n",
    "    plot_roc_curve(y_test, y_pred)\n",
    "    visualize_predictions(y_test, y_pred)\n",
    "    \n",
    "    # Print best outcomes\n",
    "    print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
