{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "! pip install tensorflow scikit-image tqdm matplotlib CairoSVG svglib reportlab keras --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of path/Data/Clean/timestamp_1:\n",
      "timestamp_1/\n",
      "    channel_0.png\n",
      "    channel_1.png\n",
      "    channel_10.png\n",
      "    channel_11.png\n",
      "    channel_2.png\n",
      "    channel_3.png\n",
      "    channel_4.png\n",
      "    channel_5.png\n",
      "    channel_6.png\n",
      "    channel_7.png\n",
      "    channel_8.png\n",
      "    channel_9.png\n",
      "    label.png\n",
      "\n",
      "Loading dataset...\n",
      "Searching for data in: path/Data/Clean/timestamp_1\n",
      "Loaded channel 0: path/Data/Clean/timestamp_1\\channel_0.png\n",
      "Loaded channel 1: path/Data/Clean/timestamp_1\\channel_1.png\n",
      "Loaded channel 2: path/Data/Clean/timestamp_1\\channel_2.png\n",
      "Loaded channel 3: path/Data/Clean/timestamp_1\\channel_3.png\n",
      "Loaded channel 4: path/Data/Clean/timestamp_1\\channel_4.png\n",
      "Loaded channel 5: path/Data/Clean/timestamp_1\\channel_5.png\n",
      "Loaded channel 6: path/Data/Clean/timestamp_1\\channel_6.png\n",
      "Loaded channel 7: path/Data/Clean/timestamp_1\\channel_7.png\n",
      "Loaded channel 8: path/Data/Clean/timestamp_1\\channel_8.png\n",
      "Loaded channel 9: path/Data/Clean/timestamp_1\\channel_9.png\n",
      "Loaded channel 10: path/Data/Clean/timestamp_1\\channel_10.png\n",
      "Loaded channel 11: path/Data/Clean/timestamp_1\\channel_11.png\n",
      "Successfully created image stack with shape: (32, 12, 4, 12)\n",
      "Loaded label: path/Data/Clean/timestamp_1\\label.png\n",
      "Total image stacks loaded: 1\n",
      "Total labels loaded: 1\n",
      "\n",
      "Number of samples: 1\n",
      "Shape of first image stack: (32, 12, 4, 12)\n",
      "Shape of first label: (32, 12, 4)\n",
      "\n",
      "Preparing data for model...\n",
      "Images shape: (1, 32, 12, 4, 12)\n",
      "Labels shape before reshape: (1, 32, 12, 4)\n",
      "Labels unique values: [9.05198467e-05 9.06045389e-05 9.32978146e-05 9.47693552e-05\n",
      " 1.00503174e-04 1.00810699e-04 1.00829522e-04 1.02745493e-04\n",
      " 1.05570514e-04 1.05938016e-04 1.13450908e-04 1.16275922e-04\n",
      " 1.16463605e-04 1.16510797e-04 1.16516443e-04 1.16539020e-04\n",
      " 1.25517967e-04 1.25534905e-04 1.26182655e-04 1.35348411e-04\n",
      " 1.36846400e-04 1.37754498e-04 1.38408315e-04 1.38856616e-04\n",
      " 1.39281197e-04 1.39486685e-04 1.39612792e-04 1.41811703e-04\n",
      " 1.41828641e-04 1.48881591e-04 1.51538086e-04 1.51706612e-04\n",
      " 1.52726570e-04 1.52882800e-04 1.53536603e-04 1.53718196e-04\n",
      " 1.57877483e-04 1.62366981e-04 1.62383934e-04 1.64627854e-04\n",
      " 1.69828185e-04 1.72249725e-04 1.81484516e-04 1.81507101e-04\n",
      " 1.83890603e-04 1.84127741e-04 1.84544406e-04 1.84555698e-04\n",
      " 1.84563221e-04 1.84762350e-04 1.84781544e-04 1.84927951e-04\n",
      " 1.85748897e-04 1.85978482e-04 1.86789694e-04 1.87323341e-04\n",
      " 1.87492740e-04 1.87535625e-04 1.88015169e-04 1.90677049e-04\n",
      " 1.91929706e-04 1.92430452e-04 1.93442407e-04 1.96432011e-04\n",
      " 1.97688161e-04 1.99598726e-04 2.00193070e-04 2.02139490e-04\n",
      " 2.03131625e-04 2.43365910e-04 2.43859307e-04 2.46612326e-04\n",
      " 2.47099408e-04 2.47543969e-04 2.73288053e-04 2.74855207e-04\n",
      " 2.76816631e-04 2.76856124e-04 2.77437677e-04 2.77567538e-04\n",
      " 2.87289877e-04 2.94904195e-04 2.96741026e-04 2.96757935e-04\n",
      " 2.96902668e-04 3.17617320e-04 3.18746694e-04 3.19348706e-04\n",
      " 3.22298903e-04 3.22355365e-04 3.22361040e-04 3.22465290e-04\n",
      " 3.22924461e-04 3.22952721e-04 3.23541753e-04 3.24311492e-04\n",
      " 3.29423929e-04 3.31685587e-04 3.33637319e-04 3.33765813e-04\n",
      " 3.36114579e-04 3.36424448e-04 3.36452300e-04 3.36493686e-04\n",
      " 3.38764250e-04 3.50094459e-04 3.70914931e-04 3.73808696e-04\n",
      " 3.78132449e-04 3.78739904e-04 3.85358115e-04 3.87684588e-04\n",
      " 3.98301170e-04 4.13123751e-04 4.26502869e-04 4.33040172e-04\n",
      " 4.57086484e-04 4.62551834e-04 4.80607530e-04 4.95903019e-04\n",
      " 4.99060377e-04 5.00196649e-04 5.35139756e-04 5.35297790e-04\n",
      " 5.35685511e-04 5.47676464e-04 5.82603272e-04 6.02918095e-04\n",
      " 6.06690417e-04 6.23722968e-04 6.36019220e-04 6.50610193e-04\n",
      " 6.63247658e-04 6.63341780e-04 6.85430947e-04 7.68135244e-04\n",
      " 7.71758787e-04 7.80258153e-04 7.81600247e-04 7.84723205e-04\n",
      " 7.91969826e-04 7.98170338e-04 8.05529649e-04 8.09743069e-04\n",
      " 8.28743388e-04 8.34752456e-04 8.62390618e-04 8.68189440e-04\n",
      " 8.72218458e-04 8.76218663e-04 8.91528733e-04 8.91930715e-04\n",
      " 8.91964650e-04 8.91998527e-04 8.92566342e-04 8.97658698e-04\n",
      " 9.02437954e-04 9.04322427e-04 9.08228976e-04 9.15126526e-04\n",
      " 9.15732060e-04 9.15963319e-04 9.24520718e-04 9.29595437e-04\n",
      " 9.35366203e-04 9.35396121e-04 9.35677497e-04 9.36745724e-04\n",
      " 9.37317032e-04 9.37322737e-04 9.37446952e-04 9.38100740e-04\n",
      " 9.38176003e-04 9.39386140e-04 9.39729391e-04 9.49447509e-04\n",
      " 9.50262067e-04 9.59958066e-04 9.63393948e-04 9.64113453e-04\n",
      " 9.64459730e-04 9.69329791e-04 9.71467758e-04 9.73515096e-04\n",
      " 9.98780946e-04 1.02398673e-03 1.02399616e-03 1.02707627e-03\n",
      " 1.03748252e-03 1.07812567e-03 1.08774938e-03 1.11817487e-03\n",
      " 1.12478575e-03 1.13314600e-03 1.13479677e-03 1.15073961e-03\n",
      " 1.16850389e-03 1.16928096e-03 1.17155921e-03 1.17246376e-03\n",
      " 1.18320261e-03 1.21416769e-03 1.22028729e-03 1.23589637e-03\n",
      " 1.23604108e-03 1.25213829e-03 1.25380594e-03 1.26051600e-03\n",
      " 1.26061752e-03 1.26076175e-03 1.26105349e-03 1.26414443e-03\n",
      " 1.26619381e-03 1.26727822e-03 1.26740721e-03 1.26884389e-03\n",
      " 1.26954855e-03 1.27012422e-03 1.28226716e-03 1.28239475e-03\n",
      " 1.28491910e-03 1.29126769e-03 1.29137491e-03 1.29153801e-03\n",
      " 1.29167608e-03 1.29167805e-03 1.29180145e-03 1.29181088e-03\n",
      " 1.38232426e-03 1.38248806e-03 1.39363832e-03 1.41929986e-03\n",
      " 1.46672153e-03 1.46968395e-03 1.49367820e-03 1.49834424e-03\n",
      " 1.58821431e-03 1.61936774e-03 1.61950896e-03 1.62802369e-03\n",
      " 1.65418326e-03 1.65438652e-03 1.65441656e-03 1.65569561e-03\n",
      " 1.66361907e-03 1.66373199e-03 1.66526670e-03 1.66641478e-03\n",
      " 1.67083682e-03 1.67089328e-03 1.67096942e-03 1.67423335e-03\n",
      " 1.67423906e-03 1.68396160e-03 1.68454682e-03 1.69705309e-03\n",
      " 1.70737947e-03 1.71847793e-03 1.72717578e-03 1.73336943e-03\n",
      " 1.74963532e-03 1.75498205e-03 1.76326907e-03 1.76930986e-03\n",
      " 1.79037685e-03 1.80703285e-03 1.84959767e-03 1.86857954e-03\n",
      " 1.87172100e-03 1.87329378e-03 1.88412669e-03 1.93727796e-03\n",
      " 1.94284134e-03 1.95849175e-03 1.95901142e-03 1.95916789e-03\n",
      " 1.96010759e-03 1.96621800e-03 1.96629437e-03 1.96836446e-03\n",
      " 1.96847389e-03 1.96849438e-03 1.96857518e-03 1.96864293e-03\n",
      " 1.96868251e-03 1.96886878e-03 1.96895376e-03 1.96911697e-03\n",
      " 1.96911884e-03 1.96919707e-03 1.97083596e-03 1.97132863e-03\n",
      " 1.97152491e-03 1.97207811e-03 1.97309535e-03 1.97528047e-03\n",
      " 1.97528605e-03 1.97546533e-03 1.97556894e-03 1.97698991e-03\n",
      " 1.97762693e-03 1.97795779e-03 1.98013708e-03 1.98014267e-03\n",
      " 1.98018225e-03 1.98219740e-03 1.98232196e-03 1.98237295e-03\n",
      " 1.98244746e-03 1.98275317e-03 1.98281137e-03 1.98285305e-03\n",
      " 1.98287168e-03 1.98442792e-03 1.98591384e-03 1.98612642e-03\n",
      " 1.98662421e-03 1.98789779e-03 1.98853482e-03 1.99395558e-03\n",
      " 1.99895236e-03 2.00529187e-03 2.00706278e-03 2.00786814e-03\n",
      " 2.01157900e-03 2.01547099e-03 2.01641559e-03 2.01734924e-03\n",
      " 2.03053257e-03 2.05135718e-03 2.05338793e-03 2.05599098e-03\n",
      " 2.05644313e-03 2.06145016e-03 2.06317566e-03 2.07722653e-03\n",
      " 2.07962678e-03 2.08028266e-03 2.08132737e-03 2.08478118e-03\n",
      " 2.09426973e-03 2.09629862e-03 2.10516574e-03 2.10569915e-03\n",
      " 2.10649869e-03 2.10883259e-03 2.11151689e-03 2.11420073e-03\n",
      " 2.11509969e-03 2.11660680e-03 2.11674790e-03 2.11954233e-03\n",
      " 2.11978122e-03 2.11990532e-03 2.12171650e-03 2.12177983e-03\n",
      " 2.12183618e-03 2.12199194e-03 2.12199753e-03 2.12208787e-03\n",
      " 2.12224922e-03 2.12226086e-03 2.12228880e-03 2.12257658e-03\n",
      " 2.12335400e-03 2.12348206e-03 2.12469487e-03 2.12760922e-03\n",
      " 2.12849560e-03 2.13216641e-03 2.13273987e-03 2.13490007e-03\n",
      " 2.14170152e-03 2.14919518e-03 2.16351403e-03 2.16949591e-03\n",
      " 2.17136671e-03 2.17362400e-03 2.17690831e-03 2.17723567e-03\n",
      " 2.18072440e-03 2.18269904e-03 2.18299450e-03 2.18377565e-03\n",
      " 2.18994077e-03 2.19137874e-03 2.19150097e-03 2.19221599e-03\n",
      " 2.19382509e-03 2.19914969e-03 2.20813765e-03 2.21173232e-03\n",
      " 2.21943459e-03 2.22020270e-03 2.22453102e-03 2.22652964e-03\n",
      " 2.22929032e-03 2.22931802e-03 2.24050158e-03 2.24811910e-03\n",
      " 2.25125253e-03 2.25314754e-03 2.25712871e-03 2.26046564e-03\n",
      " 2.26530153e-03 2.28096917e-03 2.28114636e-03 2.29036971e-03\n",
      " 2.29142653e-03 2.29977048e-03 2.30857823e-03 2.31003109e-03\n",
      " 2.34414986e-03 2.35230103e-03 2.38442211e-03 2.38847523e-03\n",
      " 2.39003124e-03 2.39152391e-03 2.39692884e-03 2.41379603e-03\n",
      " 2.42776610e-03 2.43779086e-03 2.44894251e-03 2.45490856e-03\n",
      " 2.45500240e-03 2.46949284e-03 2.47169216e-03 2.47519999e-03\n",
      " 2.49065529e-03 2.49744463e-03 2.50487216e-03 2.50530895e-03\n",
      " 2.53488659e-03 2.54903478e-03 2.55026459e-03 2.56921444e-03\n",
      " 2.57743127e-03 2.57777004e-03 2.58307764e-03 2.59192334e-03\n",
      " 2.59323511e-03 2.59418879e-03 2.59817811e-03 2.59923050e-03\n",
      " 2.60122889e-03 2.60373927e-03 2.60522589e-03 2.61058542e-03\n",
      " 2.61220569e-03 2.61239079e-03 2.61398382e-03 2.61429138e-03\n",
      " 2.61435099e-03 2.61436962e-03 2.61437916e-03 2.61439779e-03\n",
      " 2.61453004e-03 2.61524552e-03 2.61525088e-03 2.64294562e-03\n",
      " 2.64895498e-03 2.65008723e-03 2.65628099e-03 2.65743514e-03\n",
      " 2.65784888e-03 2.65808380e-03 2.66793254e-03 2.66954768e-03\n",
      " 2.67417938e-03 2.67541851e-03 2.67545809e-03 2.67585623e-03\n",
      " 2.67589395e-03 2.68041994e-03 2.69466522e-03 2.69692927e-03\n",
      " 2.71556526e-03 2.71953805e-03 2.75547244e-03 2.75694812e-03\n",
      " 2.78642890e-03 2.79234629e-03 2.81186146e-03 2.82719242e-03\n",
      " 2.83634500e-03 2.84039811e-03 2.88562267e-03 2.89012305e-03\n",
      " 2.89874896e-03 2.91695888e-03 2.91772583e-03 2.92493752e-03\n",
      " 2.93725077e-03 2.94008153e-03 2.94398330e-03 2.94753537e-03\n",
      " 2.97989161e-03 3.02448636e-03 3.04869376e-03 3.06488178e-03\n",
      " 3.06496653e-03 3.06705595e-03 3.08003672e-03 3.08507937e-03\n",
      " 3.09643662e-03 3.09693511e-03 3.11409752e-03 3.11716599e-03\n",
      " 3.11725982e-03 3.14053940e-03 3.15647479e-03 3.15796281e-03\n",
      " 3.16101802e-03 3.16599524e-03 3.18250665e-03 3.19242221e-03\n",
      " 3.19293770e-03 3.19440733e-03 3.19449743e-03 3.19649582e-03\n",
      " 3.21217044e-03 3.21330130e-03 3.21405428e-03 3.21409549e-03\n",
      " 3.21412762e-03 3.21412948e-03 3.21414834e-03 3.21542774e-03\n",
      " 3.21545592e-03 3.21941380e-03 3.23049724e-03 3.23961605e-03\n",
      " 3.26015498e-03 3.26297176e-03 3.26426141e-03 3.26921395e-03\n",
      " 3.27747944e-03 3.27855325e-03 3.27904522e-03 3.27935861e-03\n",
      " 3.27959307e-03 3.27967154e-03 3.30419047e-03 3.30615742e-03\n",
      " 3.30620259e-03 3.30637372e-03 3.30642075e-03 3.32616083e-03\n",
      " 3.33778304e-03 3.35263973e-03 3.35368654e-03 3.37231089e-03\n",
      " 3.37284431e-03 3.37360147e-03 3.38359340e-03 3.38958902e-03\n",
      " 3.39156459e-03 3.39558418e-03 3.41127859e-03 3.41130956e-03\n",
      " 3.41145881e-03 3.41338944e-03 3.41349305e-03 3.41397617e-03\n",
      " 3.41398688e-03 3.41406208e-03 3.41407163e-03 3.41513869e-03\n",
      " 3.41516128e-03 3.41993454e-03 3.45278974e-03 3.46525549e-03\n",
      " 3.46776308e-03 3.46800708e-03 3.46803875e-03 3.46823270e-03\n",
      " 3.46846762e-03 3.46935401e-03 3.47660994e-03 3.48122162e-03\n",
      " 3.48896813e-03 3.49072460e-03 3.49074719e-03 3.49089922e-03\n",
      " 3.49096511e-03 3.55790579e-03 3.57157574e-03 3.57370800e-03\n",
      " 3.57440044e-03 3.57543933e-03 3.58271133e-03 3.58291296e-03\n",
      " 3.58754676e-03 3.58976587e-03 3.58988368e-03 3.59575730e-03\n",
      " 3.59641970e-03 3.59686371e-03 3.59698408e-03 3.59734171e-03\n",
      " 3.59850307e-03 3.59861599e-03 3.60026886e-03 3.60027468e-03\n",
      " 3.60035943e-03 3.62630235e-03 3.63051565e-03 3.64209688e-03\n",
      " 3.69310449e-03 3.69371660e-03 3.70975793e-03 3.72142764e-03\n",
      " 3.72156082e-03 3.72163439e-03 3.72164557e-03]\n",
      "Labels shape after reshape: (1, 1536)\n",
      "Warning: Only 1 samples found. Splitting may not be possible.\n",
      "X_train shape: (1, 32, 12, 4, 12)\n",
      "y_train shape: (1, 1536)\n",
      "X_val shape: (1, 32, 12, 4, 12)\n",
      "y_val shape: (1, 1536)\n",
      "\n",
      "Training samples: 1\n",
      "Validation samples: 1\n",
      "Test samples: 1\n",
      "Training model...\n",
      "Batch images shape: (1, 32, 12, 4, 12)\n",
      "Batch labels shape: (1, 1536)\n",
      "Batch images shape: (1, 32, 12, 4, 12)\n",
      "Batch labels shape: (1, 1536)\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion\n",
    "\n",
    "def load_and_preprocess_image(file_path, target_size=(32, 32)):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single satellite image.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the image file.\n",
    "        target_size (tuple): Desired size of the output image (height, width).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed image as a numpy array.\n",
    "\n",
    "    This function loads an image from the given file path, resizes it to the specified\n",
    "    target size, and normalizes the pixel values to the range [0, 1].\n",
    "    \"\"\"\n",
    "    img = io.imread(file_path)\n",
    "    img = transform.resize(img, target_size, anti_aliasing=True)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "def load_dataset(data_dir, target_size=(32, 32)):\n",
    "    \"\"\"\n",
    "    Load all images and labels from the data directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the directory containing the dataset.\n",
    "        target_size (tuple): Desired size of the output images (height, width).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two numpy arrays, (images, labels).\n",
    "            - images: 4D array of shape (n_samples, height, width, channels)\n",
    "            - labels: 3D array of shape (n_samples, height, width)\n",
    "\n",
    "    This function loads all image channels and corresponding labels from the specified\n",
    "    directory. It handles both single timestamp and multiple timestamp directory structures.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"Searching for data in: {data_dir}\")\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: Directory {data_dir} does not exist.\")\n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    # Check if data_dir is a single timestamp directory or contains multiple timestamp directories\n",
    "    if all(f.startswith('channel_') or f == 'label.png' for f in os.listdir(data_dir)):\n",
    "        # Single timestamp directory\n",
    "        directories = [data_dir]\n",
    "    else:\n",
    "        # Multiple timestamp directories\n",
    "        directories = [os.path.join(data_dir, d) for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    \n",
    "    for directory in directories:\n",
    "        timestamp_images = []\n",
    "        for i in range(12):\n",
    "            img_path = os.path.join(directory, f'channel_{i}.png')\n",
    "            if os.path.exists(img_path):\n",
    "                img = load_and_preprocess_image(img_path, target_size)\n",
    "                timestamp_images.append(img)\n",
    "                print(f\"Loaded channel {i}: {img_path}\")\n",
    "            else:\n",
    "                print(f\"Missing image: {img_path}\")\n",
    "        \n",
    "        if len(timestamp_images) == 12:\n",
    "            image_stack = np.stack(timestamp_images, axis=-1)\n",
    "            images.append(image_stack)\n",
    "            print(f\"Successfully created image stack with shape: {image_stack.shape}\")\n",
    "            \n",
    "            label_path = os.path.join(directory, 'label.png')\n",
    "            if os.path.exists(label_path):\n",
    "                label = io.imread(label_path)\n",
    "                label = load_and_preprocess_image(label_path, target_size)\n",
    "                labels.append(label)\n",
    "                print(f\"Loaded label: {label_path}\")\n",
    "            else:\n",
    "                print(f\"Missing label: {label_path}\")\n",
    "        else:\n",
    "            print(f\"Incomplete channel set in {directory}. Found {len(timestamp_images)} channels instead of 12.\")\n",
    "    \n",
    "    print(f\"Total image stacks loaded: {len(images)}\")\n",
    "    print(f\"Total labels loaded: {len(labels)}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def prepare_data_for_model(images, labels, test_size=0.2, validation_split=0.2):\n",
    "    \"\"\"\n",
    "    Prepare the data for model training, including train/val/test split.\n",
    "\n",
    "    Args:\n",
    "        images (numpy.ndarray): 4D array of input images.\n",
    "        labels (numpy.ndarray): 3D array of corresponding labels.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "        validation_split (float): Proportion of the training data to include in the validation split.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Six numpy arrays, (X_train, X_val, X_test, y_train, y_val, y_test).\n",
    "\n",
    "    This function splits the dataset into training, validation, and test sets. It also\n",
    "    performs some data integrity checks and reshapes the labels if necessary.\n",
    "    \"\"\"\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape before reshape: {labels.shape}\")\n",
    "    print(f\"Labels unique values: {np.unique(labels)}\")\n",
    "\n",
    "    if labels.size == 0:\n",
    "        raise ValueError(\"Labels array is empty. Please check the data loading process.\")\n",
    "\n",
    "    labels = labels.reshape(labels.shape[0], -1)\n",
    "    print(f\"Labels shape after reshape: {labels.shape}\")\n",
    "\n",
    "    n_samples = len(images)\n",
    "    if n_samples < 3:\n",
    "        print(f\"Warning: Only {n_samples} samples found. Splitting may not be possible.\")\n",
    "        return images, images, images, labels, labels, labels\n",
    "\n",
    "    if n_samples < 10:\n",
    "        print(f\"Warning: Only {n_samples} samples found. Using a 60/20/20 split.\")\n",
    "        test_size = 0.2\n",
    "        validation_split = 0.25  # 25% of 80% is 20% of the total\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        images, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=validation_split, random_state=42)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def data_generator(images, labels, class_weights, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generate batches of data with class weights for training.\n",
    "\n",
    "    Args:\n",
    "        images (numpy.ndarray): 4D array of input images.\n",
    "        labels (numpy.ndarray): 2D array of corresponding labels.\n",
    "        class_weights (dict): Dictionary mapping class indices to class weights.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "\n",
    "    Yields:\n",
    "        tuple: (batch_images, batch_labels, batch_weights)\n",
    "            - batch_images: numpy array of shape (batch_size, height, width, channels)\n",
    "            - batch_labels: numpy array of shape (batch_size, num_classes)\n",
    "            - batch_weights: numpy array of shape (batch_size,) containing sample weights\n",
    "\n",
    "    This generator function creates balanced batches of data for training, applying\n",
    "    class weights to handle imbalanced datasets.\n",
    "    \"\"\"\n",
    "    num_samples = len(images)\n",
    "    while True:\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_images = images[batch_indices]\n",
    "            batch_labels = labels[batch_indices]\n",
    "            print(\"Batch images shape:\", batch_images.shape)\n",
    "            print(\"Batch labels shape:\", batch_labels.shape)\n",
    "            batch_weights = np.array([class_weights[label] for label in batch_labels.flatten()])\n",
    "            yield batch_images, batch_labels, batch_weights\n",
    "\n",
    "# Model Architecture\n",
    "\n",
    "def create_lightning_cnn(input_shape=(32, 32, 12), num_classes=1024):\n",
    "    \"\"\"\n",
    "    Create a CNN model for lightning detection.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input images (height, width, channels).\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: Compiled Keras model.\n",
    "\n",
    "    This function creates a simple CNN architecture for lightning detection in satellite imagery.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        \n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compile_model(model, learning_rate=1e-3, decay=0.9):\n",
    "    \"\"\"\n",
    "    Compile the Keras model with appropriate optimizer and loss function.\n",
    "\n",
    "    Args:\n",
    "        model (tensorflow.keras.Model): The model to compile.\n",
    "        learning_rate (float): Initial learning rate for the optimizer.\n",
    "        decay (float): Decay rate for the learning rate schedule.\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: Compiled Keras model.\n",
    "\n",
    "    This function sets up the model with an Adam optimizer with learning rate decay,\n",
    "    binary crossentropy loss, and various metrics.\n",
    "    \"\"\"\n",
    "    lr_schedule = optimizers.schedules.InverseTimeDecay(\n",
    "        initial_learning_rate=learning_rate,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=decay\n",
    "    )\n",
    "    optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Model Training\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size=128, epochs=10):\n",
    "    \"\"\"\n",
    "    Train the model on the provided data.\n",
    "\n",
    "    Args:\n",
    "        model (tensorflow.keras.Model): The model to train.\n",
    "        X_train (numpy.ndarray): Training data.\n",
    "        y_train (numpy.ndarray): Training labels.\n",
    "        X_val (numpy.ndarray): Validation data.\n",
    "        y_val (numpy.ndarray): Validation labels.\n",
    "        batch_size (int): Number of samples per gradient update.\n",
    "        epochs (int): Number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.callbacks.History: Training history object.\n",
    "\n",
    "    This function trains the model using the provided data, implements early stopping\n",
    "    and learning rate reduction, and uses class weights to handle imbalanced data.\n",
    "    \"\"\"\n",
    "    # Calculate class weights\n",
    "    unique, counts = np.unique(y_train.flatten(), return_counts=True)\n",
    "    class_weights = dict(zip(unique, len(y_train.flatten()) / (len(unique) * counts)))\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.2, patience=20)\n",
    "\n",
    "    train_gen = data_generator(X_train, y_train, class_weights, batch_size)\n",
    "    val_gen = data_generator(X_val, y_val, class_weights, batch_size)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=len(X_train) // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=len(X_val) // batch_size,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def create_custom_cnn(input_shape=(32, 12, 4, 12), num_classes=1024):\n",
    "    \"\"\"\n",
    "    Create a custom CNN model for lightning detection.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input images (height, width, time, channels).\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: Compiled Keras model.\n",
    "\n",
    "    This function creates a more complex CNN architecture for lightning detection,\n",
    "    designed to handle multi-channel, multi-temporal satellite imagery.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Reshape the input to combine the 12 and 4 dimensions\n",
    "    x = layers.Reshape((32, 12, 48))(inputs)\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Performance Visualization\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot the training history of the model.\n",
    "\n",
    "    Args:\n",
    "        history (tensorflow.keras.callbacks.History): History object returned by model.fit().\n",
    "\n",
    "    This function creates two subplots: one for accuracy and one for loss,\n",
    "    showing both training and validation metrics over epochs.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Plot the precision-recall curve.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): True labels.\n",
    "        y_pred (numpy.ndarray): Predicted probabilities or scores.\n",
    "\n",
    "    This function calculates and plots the precision-recall curve, which shows the\n",
    "    trade-off between precision and recall for different threshold values.\n",
    "    \"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(y_true.ravel(), y_pred.ravel())\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Plot the Receiver Operating Characteristic (ROC) curve.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): True labels.\n",
    "        y_pred (numpy.ndarray): Predicted probabilities or scores.\n",
    "\n",
    "    This function calculates and plots the ROC curve, which illustrates the diagnostic\n",
    "    ability of a binary classifier system as its discrimination threshold is varied.\n",
    "    It also calculates and displays the Area Under the Curve (AUC) score.\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(y_true, y_pred, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize the true labels and model predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): True labels.\n",
    "        y_pred (numpy.ndarray): Predicted labels or probabilities.\n",
    "        num_samples (int): Number of random samples to visualize.\n",
    "\n",
    "    This function randomly selects a specified number of samples and displays\n",
    "    their true labels alongside the model's predictions for visual comparison.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(0, y_true.shape[0])\n",
    "        \n",
    "        axes[i, 0].imshow(y_true[idx].reshape(32, 32), cmap='binary')\n",
    "        axes[i, 0].set_title(f'True - Sample {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(y_pred[idx].reshape(32, 32), cmap='binary')\n",
    "        axes[i, 1].set_title(f'Predicted - Sample {i+1}')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main Execution\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main execution block for the lightning detection model.\n",
    "\n",
    "    This block demonstrates the full pipeline of the lightning detection model:\n",
    "    1. Data loading and preprocessing\n",
    "    2. Model creation and compilation\n",
    "    3. Model training\n",
    "    4. Model evaluation\n",
    "    5. Visualization of results\n",
    "\n",
    "    It serves as an example of how to use the various functions defined in this script\n",
    "    to train and evaluate a lightning detection model on satellite imagery data.\n",
    "    \"\"\"\n",
    "    # Data Ingestion\n",
    "    data_dir = 'path/Data/Clean/timestamp_1'\n",
    "    target_size = (32, 12)\n",
    "    batch_size = 32\n",
    "    \n",
    "    print(f\"Contents of {data_dir}:\")\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        level = root.replace(data_dir, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f\"{subindent}{f}\")\n",
    "    \n",
    "    print(\"\\nLoading dataset...\")\n",
    "    images, labels = load_dataset(data_dir, target_size)\n",
    "    \n",
    "    print(f\"\\nNumber of samples: {len(images)}\")\n",
    "    print(f\"Shape of first image stack: {images[0].shape if len(images) > 0 else 'No images'}\")\n",
    "    print(f\"Shape of first label: {labels[0].shape if len(labels) > 0 else 'No labels'}\")\n",
    "\n",
    "    if len(images) == 0 or len(labels) == 0:\n",
    "        print(\"Error: No images or labels were loaded. Please check the data directory and file structure.\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"\\nPreparing data for model...\")\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_for_model(images, labels)\n",
    "    \n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"X_val shape:\", X_val.shape)\n",
    "    print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "    print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "    print(f\"Validation samples: {len(X_val)}\")\n",
    "    print(f\"Test samples: {len(X_test)}\")\n",
    "    \n",
    "    # Model Creation and Training\n",
    "    input_shape = X_train.shape[1:]  # Dynamically set the input shape\n",
    "    num_classes = y_train.shape[1] \n",
    "    \n",
    "    model = create_custom_cnn(input_shape, num_classes)\n",
    "    model = compile_model(model)\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    print(\"Evaluating model...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    \n",
    "    # Generate predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Visualize Results\n",
    "    plot_training_history(history)\n",
    "    plot_precision_recall_curve(y_test, y_pred)\n",
    "    plot_roc_curve(y_test, y_pred)\n",
    "    visualize_predictions(y_test, y_pred)\n",
    "    \n",
    "    # Print best outcomes\n",
    "    print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_predictions(predictions, threshold=0.5, min_area=10):\n",
    "    \"\"\"\n",
    "    Post-process the model's predictions to identify significant lightning areas.\n",
    "\n",
    "    Args:\n",
    "        predictions (numpy.ndarray): Raw predictions from the model (probability maps).\n",
    "        threshold (float): Probability threshold for considering a pixel as lightning.\n",
    "        min_area (int): Minimum area (in pixels) for a region to be considered significant.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Binary mask of significant lightning areas.\n",
    "    \"\"\"\n",
    "    # Apply threshold to get binary prediction\n",
    "    binary_pred = (predictions > threshold).astype(np.uint8)\n",
    "\n",
    "    # Label connected components\n",
    "    labeled, num_features = ndimage.label(binary_pred)\n",
    "\n",
    "    # Remove small areas\n",
    "    for i in range(1, num_features + 1):\n",
    "        area = np.sum(labeled == i)\n",
    "        if area < min_area:\n",
    "            binary_pred[labeled == i] = 0\n",
    "\n",
    "    return binary_pred\n",
    "\n",
    "def get_lightning_regions(binary_pred):\n",
    "    \"\"\"\n",
    "    Get the bounding boxes of lightning regions.\n",
    "\n",
    "    Args:\n",
    "        binary_pred (numpy.ndarray): Binary mask of lightning areas.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples, each containing (min_row, min_col, max_row, max_col) for a lightning region.\n",
    "    \"\"\"\n",
    "    labeled, num_features = ndimage.label(binary_pred)\n",
    "    regions = []\n",
    "\n",
    "    for i in range(1, num_features + 1):\n",
    "        rows, cols = np.where(labeled == i)\n",
    "        min_row, max_row = np.min(rows), np.max(rows)\n",
    "        min_col, max_col = np.min(cols), np.max(cols)\n",
    "        regions.append((min_row, min_col, max_row, max_col))\n",
    "\n",
    "    return regions\n",
    "\n",
    "# Example usage\n",
    "y_pred = model.predict(X_test)  # Assuming X_test is your test data\n",
    "\n",
    "for i, pred in enumerate(y_pred):\n",
    "    # Post-process the prediction\n",
    "    processed_pred = post_process_predictions(pred, threshold=0.5, min_area=10)\n",
    "    \n",
    "    # Get lightning regions\n",
    "    lightning_regions = get_lightning_regions(processed_pred)\n",
    "    \n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    if lightning_regions:\n",
    "        print(f\"  Found {len(lightning_regions)} significant lightning areas:\")\n",
    "        for j, region in enumerate(lightning_regions):\n",
    "            print(f\"    Region {j + 1}: {region}\")\n",
    "    else:\n",
    "        print(\"  No significant lightning areas detected.\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
